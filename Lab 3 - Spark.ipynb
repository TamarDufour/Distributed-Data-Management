{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0eadc202",
   "metadata": {},
   "source": [
    "## Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5485cf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://IdeaPad5:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>lab3</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=lab3>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "def init_spark(app_name: str):\n",
    "    spark = SparkSession.builder.appName(app_name).getOrCreate()\n",
    "    sc = spark.sparkContext\n",
    "    return spark, sc\n",
    "\n",
    "spark, sc = init_spark('lab3')\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13e07a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.5E+14 97.64285714285714\n",
      "7.46E+14 11.714285714285714\n",
      "7.503E+14 9.357142857142858\n",
      "8.00001E+11 7.5\n",
      "8.4843E+14 5.5\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "\n",
    "sc = SparkContext.getOrCreate()\n",
    "\n",
    "data_csv = 'Lab3_view_data.csv'\n",
    "data_rdd = sc.textFile(data_csv)\n",
    "data_rdd = data_rdd.map(lambda row: row.split(',')) #split by comma\n",
    "header = data_rdd.first()\n",
    "data_rdd2 = data_rdd.filter(lambda row: row != header) #remove the header\n",
    "\n",
    "#Finds the number of viewing events for each device in each day during Prime-Time (20:00-23:00):\n",
    "prime_time_data = data_rdd2.filter(lambda row: int(row[3])>=200000 and int(row[3])<230000)\n",
    "\n",
    "#Sorts the data according to views per device:\n",
    "sorted_data = prime_time_data.map(lambda x:(x[1],1)).reduceByKey( lambda x,y:x+y).sortBy( lambda x: -x[1])\n",
    "sorted_data.collect()\n",
    "top_5_devices = (sorted_data.take(5))\n",
    "\n",
    "#Calculates the number of different dates in the data:\n",
    "all_dates = data_rdd2.map(lambda x:(x[2], 1)).reduceByKey(lambda x,y: x+y)\n",
    "all_dates.collect()\n",
    "all_dates_num = all_dates.count()\n",
    "\n",
    "#Return the devices and the average amount of viewing events during PrimeTime across all the dates in the data,\n",
    "#of the 5 devices with the highest averages\n",
    "for i in top_5_devices:\n",
    "    print(f\"{i[0]}\" + f\" {i[1]/all_dates_num}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
